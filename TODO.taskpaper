Scraping Gnipe:
    - scraper daemon @done(2009-02-21 15:22:46)
    - emits 'parse' events for files that need to be parsed @done(2009-02-21 15:28:22)

Emitting Queue Events:
    - parser to parse the xml @done(2009-02-21 11:17:27)
    - event class  @done(2009-02-21 11:17:41)
    - daemon process to read from gnip-parse and emit to gnip-activity @done(2009-02-22 01:24:22)

Consuming and inserting int Couchdb:
    - tweet model to hold data  @done(2009-02-22 01:24:40)
    - fetcher to go get the tweet from upstream @done(2009-02-22 01:25:27)
    - submiter to take the tweet and put it into couchdb @done(2009-02-23 21:46:11)
    - commandline program to loop over the beanstalkd queue until empty @done(2009-02-23 21:46:13)

Viewing:
    - different databases for users ?
    - views in couchdb to show rollups @done(2009-02-23 21:46:16)
    - couchapp @done(2009-02-23 21:46:18)

Other:
    - change to have another queue between the tweet fetchers and the store
    - change stages to:
        - gnip/scraper.rb -> gnip/consume.rb @done(2009-02-25 01:59:24)
        - notify -> 'consume' @done(2009-02-25 01:59:26)
        - split @done(2009-02-25 01:59:27)
        - scrape -- start here, making sure the scrape command is all good @done(2009-02-28 11:21:16)
            - fix the daemonize pid so that more than one daemon can exist at once @done(2009-02-28 11:21:10)
            - have counters for the other errors that are retrieved. @done(2009-02-28 01:11:59)
        - store
            - a tyrant server, using table format, adding indexes on 
                - author name
                - hashtag
                - source
                - mentions
        - publish
            - have a gnip publication document
            - publish to multiple locations, one for rollowing up metrics( couch
              ? )
    - is scraping twitter okay according to twitter terms of service @done(2009-02-25 01:59:31)
    - change queues to  @done(2009-02-23 23:13:48)
        - split @done(2009-02-23 23:13:49)
        - scrape @done(2009-02-23 23:13:51)
        - publish @done(2009-02-23 23:13:52)


        
Tables:
    Dates: 
        - key 'date/#{jd}'
        - type 'Date'
        - jd #{jd}
        - ord "yyyy-ddd"
        - iso "yyyy-mm-dd"

    Tweets:
        - key = 'tweet/#{status_id}' where id is item minux xml
        - type 'Tweet'
        - status_id
        - author (username)
        - text ( full text )
        - url
        - destinationurl
        - source
        - at
        - author_snapshot ( 'author/#{username}/#{jd}' )
        - post_date    ( julan day of at )
        - post_at      ( julian time of at )
        - split_at     ( julian time )
        - scrape_at    ( julian time )
        - store_at     ( julian time )
        - publish_at   ( julian time )
        - tags (csv)
        - mentions (csv)
        - urls (csv)

    Authors:
        - id = 'author/#{username}'
        - type 'Author'
        - username 
        - name
        - location
        - website
        - bio
        - picture_url
        - follower_count
        - following_count
        - update_count
        - first_snap_date( julian day)
        - snap_date      ( julian day )
        - snap_at        ( julian time )

    AuthorSnapshots:
        - id = 'author/#{username}/snapshot/#{jd}
        - type 'AuthorSnapshot'
        - snap_date (  jd )
        - snap_at ( julian time )
        - everything else from Authors

    Follows:
        - id = 'author/#{username}/follows/#{username}'
        - 
        - type 'Follow'
        - first_snap_date
        - last_snap_date
        - is_current



        
Gnip v2.1
    - switch to that notification stream
    - start publishing


20:53:24

